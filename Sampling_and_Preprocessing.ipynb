{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def sample_json(input_file, output_file, target_size_gb, filter_key='also_buy'):\n",
    "#     target_size_bytes = target_size_gb * 1024**3\n",
    "#     current_size_bytes = 0\n",
    "\n",
    "#     with open(input_file, 'r', encoding='utf-8') as infile, open(output_file, 'w', encoding='utf-8') as outfile:\n",
    "#         for line in tqdm(infile, desc=f\"Processing {input_file}\"):  \n",
    "#             record = json.loads(line)\n",
    "#             if record.get(filter_key):\n",
    "#                 outfile.write(json.dumps(record) + '\\n')\n",
    "#                 current_size_bytes += len(line.encode('utf-8'))\n",
    "            \n",
    "#             if current_size_bytes >= target_size_bytes:\n",
    "#                 break\n",
    "\n",
    "#     print(f\"Finished sampling. Output size: {current_size_bytes / 1024**3:.2f} GB\")\n",
    "\n",
    "# sample_json('H:\\\\All_Amazon_Meta.json', 'Sampled_Amazon_Meta.json', 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file_path = 'Sampled_Amazon_Meta.json'\n",
    "output_file_path = 'Corrected_Sample_Amazon_Meta.json'\n",
    "\n",
    "def fix_common_json_errors(line):\n",
    "    # Remove extra commas before closing brackets or braces\n",
    "    line = line.strip()\n",
    "    line = line.rstrip(',')\n",
    "    if not line.endswith('}') and not line.endswith(']'):\n",
    "        # Try adding a closing bracket if missing\n",
    "        if '{' in line and '}' not in line:\n",
    "            line += '}'\n",
    "        elif '[' in line and ']' not in line:\n",
    "            line += ']'\n",
    "    return line\n",
    "\n",
    "def process_line_by_line(input_path, output_path):\n",
    "    errors_count = 0\n",
    "    with open(input_path, 'r', encoding='utf-8') as file, \\\n",
    "         open(output_path, 'w', encoding='utf-8') as outfile:\n",
    "        for line_number, line in enumerate(file, 1):\n",
    "            try:\n",
    "                corrected_line = fix_common_json_errors(line)\n",
    "                data = json.loads(corrected_line)\n",
    "                # Write the valid JSON back to a new file\n",
    "                json.dump(data, outfile)\n",
    "                outfile.write('\\n')  # Ensure each JSON object is on a new line\n",
    "            except json.JSONDecodeError as e:\n",
    "                errors_count += 1\n",
    "                print(f\"Error in line {line_number}: {e}\")\n",
    "    print(f\"Finished processing. Total errors: {errors_count}\")\n",
    "\n",
    "process_line_by_line(input_file_path, output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading only the column names from the sampled file\n",
    "input_file = \"H:\\\\Sampled_Amazon_Meta.json\"\n",
    "with open(input_file, 'r', encoding='utf-8') as infile:\n",
    "    first_line = infile.readline()\n",
    "    column_names = list(json.loads(first_line).keys())\n",
    "\n",
    "# displaying the column names\n",
    "print(column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"Cleans text by removing unwanted HTML tags, URLs, and normalizing whitespace.\"\"\"\n",
    "    unwanted_patterns = [\n",
    "        r\"<[^>]*>\",                  # HTML tags\n",
    "        r\"https?:\\/\\/\\S+\",           # URLs\n",
    "        r\"P\\.when\\(.*?\\);\",          # JS snippets\n",
    "        r\"span class\\w+\",             # span classes\n",
    "    ]\n",
    "\n",
    "    # Drop text if any unwanted patterns are found\n",
    "    if any(re.search(pattern, text) for pattern in unwanted_patterns):\n",
    "        return \"\"\n",
    "\n",
    "    # Remove backslashes, normalize spaces, and remove non-alphanumeric characters\n",
    "    text = re.sub(r\"\\\\\", \"\", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
    "\n",
    "    return text\n",
    "\n",
    "def process_item_data(item_data):\n",
    "    \"\"\"Processes individual item data, extracting and cleaning relevant information.\"\"\"\n",
    "    # Extract and clean the necessary fields\n",
    "    asin = item_data.get(\"asin\", \"\")\n",
    "    title = clean_text(item_data.get(\"title\", \"No Title Available\"))\n",
    "    brand = item_data.get(\"brand\", \"Unknown Brand\")\n",
    "    categories = item_data.get(\"categories\", [])\n",
    "\n",
    "    # Handling related products\n",
    "    related_products = set(item_data.get(\"also_buy\", [])) | set(item_data.get(\"also_viewed\", []))\n",
    "    related = list(related_products) if related_products else []\n",
    "\n",
    "    # Prepare preprocessed item data with selected fields\n",
    "    preprocessed_item = {\n",
    "        \"asin\": asin,\n",
    "        \"title\": title,\n",
    "        \"brand\": brand,\n",
    "        \"categories\": categories,\n",
    "        \"related\": related,\n",
    "    }\n",
    "\n",
    "    return preprocessed_item\n",
    "\n",
    "input_file_path = \"H:\\\\Sampled_Amazon_Meta.json\"\n",
    "output_file_path = \"H:\\\\preprocessed_dataset.json\"\n",
    "\n",
    "with open(input_file_path, \"r\") as file_input, open(output_file_path, \"w\") as file_output:\n",
    "    file_output.write(\"[\")  # Start JSON array\n",
    "    first_item = True\n",
    "    for line in file_input:\n",
    "        raw_data = json.loads(line)\n",
    "        processed_item = process_item_data(raw_data)\n",
    "        if not first_item:\n",
    "            file_output.write(\",\\n\")\n",
    "        json.dump(processed_item, file_output)\n",
    "        first_item = False\n",
    "    file_output.write(\"]\")  # End JSON array\n",
    "\n",
    "print(\"Dataset processing complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
